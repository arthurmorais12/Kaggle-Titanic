{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd083a7b52c61ac461ecd39f01029b90745980705e00cb0438971bf5260fc8f1401",
   "display_name": "Python 3.8.8 64-bit ('TitanicProject': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Realizada a EDA e tratamento dos dados, realizarei o treinamento dos modelos. Testarei dois modelos: Regressão Logística e XGBoost."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "source": [
    "## Leitura dos dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.read_csv('dados_tratados/basecompleta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PassengerId', 'Survived', 'Pclass', 'Name', 'Age',\n",
       "       'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Cabine_nula', 'Treino',\n",
       "       'Sex_male', 'Embarked_Q', 'Embarked_S', 'Titulo_Col.',\n",
       "       'Titulo_Countess.', 'Titulo_Don.', 'Titulo_Dona.', 'Titulo_Dr.',\n",
       "       'Titulo_Jonkheer.', 'Titulo_Lady.', 'Titulo_Major.', 'Titulo_Master.',\n",
       "       'Titulo_Miss.', 'Titulo_Mlle.', 'Titulo_Mme.', 'Titulo_Mr.',\n",
       "       'Titulo_Mrs.', 'Titulo_Ms.', 'Titulo_Rev.', 'Titulo_Sir.',\n",
       "       'letra_cabine_B', 'letra_cabine_C', 'letra_cabine_D', 'letra_cabine_E',\n",
       "       'letra_cabine_F', 'letra_cabine_G', 'letra_cabine_Nula',\n",
       "       'letra_cabine_T'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dados.columns"
   ]
  },
  {
   "source": [
    "## Normalização das variáveis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "dados['Age_scaled'] = scaler.fit_transform(dados['Age'].values.reshape(-1,1))\n",
    "dados['Fare_scaled'] = scaler.fit_transform(dados['Fare'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando base de treino e base de teste\n",
    "base_treino = dados[dados['Treino'] == 1]\n",
    "base_teste = dados[dados['Treino'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 418 entries, 891 to 1308\nData columns (total 43 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Unnamed: 0         418 non-null    int64  \n 1   PassengerId        418 non-null    int64  \n 2   Survived           0 non-null      float64\n 3   Pclass             418 non-null    int64  \n 4   Name               418 non-null    object \n 5   Age                418 non-null    float64\n 6   SibSp              418 non-null    int64  \n 7   Parch              418 non-null    int64  \n 8   Ticket             418 non-null    object \n 9   Fare               418 non-null    float64\n 10  Cabin              91 non-null     object \n 11  Cabine_nula        418 non-null    int64  \n 12  Treino             418 non-null    int64  \n 13  Sex_male           418 non-null    int64  \n 14  Embarked_Q         418 non-null    int64  \n 15  Embarked_S         418 non-null    int64  \n 16  Titulo_Col.        418 non-null    int64  \n 17  Titulo_Countess.   418 non-null    int64  \n 18  Titulo_Don.        418 non-null    int64  \n 19  Titulo_Dona.       418 non-null    int64  \n 20  Titulo_Dr.         418 non-null    int64  \n 21  Titulo_Jonkheer.   418 non-null    int64  \n 22  Titulo_Lady.       418 non-null    int64  \n 23  Titulo_Major.      418 non-null    int64  \n 24  Titulo_Master.     418 non-null    int64  \n 25  Titulo_Miss.       418 non-null    int64  \n 26  Titulo_Mlle.       418 non-null    int64  \n 27  Titulo_Mme.        418 non-null    int64  \n 28  Titulo_Mr.         418 non-null    int64  \n 29  Titulo_Mrs.        418 non-null    int64  \n 30  Titulo_Ms.         418 non-null    int64  \n 31  Titulo_Rev.        418 non-null    int64  \n 32  Titulo_Sir.        418 non-null    int64  \n 33  letra_cabine_B     418 non-null    int64  \n 34  letra_cabine_C     418 non-null    int64  \n 35  letra_cabine_D     418 non-null    int64  \n 36  letra_cabine_E     418 non-null    int64  \n 37  letra_cabine_F     418 non-null    int64  \n 38  letra_cabine_G     418 non-null    int64  \n 39  letra_cabine_Nula  418 non-null    int64  \n 40  letra_cabine_T     418 non-null    int64  \n 41  Age_scaled         418 non-null    float64\n 42  Fare_scaled        418 non-null    float64\ndtypes: float64(5), int64(35), object(3)\nmemory usage: 143.7+ KB\n"
     ]
    }
   ],
   "source": [
    "base_teste.info()"
   ]
  },
  {
   "source": [
    "Irei tirar as colunas que não irei usar no treinamento do modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\art19\\anaconda3\\envs\\TitanicProject\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "base_treino.drop(['Unnamed: 0', 'Cabin', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "base_teste.drop(['Unnamed: 0', 'Cabin', 'Name', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "Separando os features da variável target."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_treino.drop(columns=['Survived', 'Age', 'Fare'], axis=1)\n",
    "y = base_treino['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "source": [
    "# Modelagem\n",
    "Serão testados três modelos: SVM, XGBoost e RandomForest.\n",
    "Começarei estimando o modelo XGBoost. Utilizarei técnicas de cross-validation para uma melhor acurácia e para melhorar os hiperparâmetros do modelo.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Treinando XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:17:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "C:\\Users\\art19\\anaconda3\\envs\\TitanicProject\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "accuracy_score(y_test, xgb_model.predict(X_test))"
   ]
  },
  {
   "source": [
    "## Treinando SVM\n",
    "Utilizarei o GridSearchCV por se tratar de poucos hiperparâmetros para serem calibrados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando SVM\n",
    "grid_params_svm = {\n",
    "    'C':[0.001, 0.01, 0.1, 1, 10],\n",
    "    'kernel':['rbf', 'linear']\n",
    "    }\n",
    "svm = SVC()\n",
    "cv_svm_model = GridSearchCV(svm, grid_params_svm, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['rbf', 'linear']})"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "cv_svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "cv_svm_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8215571205007824"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "cv_svm_model.best_score_"
   ]
  },
  {
   "source": [
    "## Treinando RandomForest\n",
    "Utilizarei técnicas de CV para calibrar os hiperparâmetros. Isso faz com que o modelo encontre uma solução melhor do que com os hiperparâmetros padrões."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param_grid_rf ={\n",
    "'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "cv_rf_model = RandomizedSearchCV(rf, param_grid_rf, cv=10, n_iter=50, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]})"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "cv_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, min_samples_leaf=4, n_estimators=200)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "cv_rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8384389671361502"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "cv_rf_model.best_score_"
   ]
  },
  {
   "source": [
    "## Predizendo base de testes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Aqui aplico o melhor modelo na base de testes, para fazer a submissão no Kaggle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_para_teste = base_teste.drop(columns=['Survived', 'Age', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dados_teste = cv_rf_model.predict(base_para_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-50-db20a25be608>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  base_teste['Survived'] = y_pred_dados_teste.astype(int)\n"
     ]
    }
   ],
   "source": [
    "base_teste['Survived'] = y_pred_dados_teste.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respostas_rf = pd.DataFrame()\n",
    "df_respostas_rf['PassengerId'] = base_teste['PassengerId']\n",
    "df_respostas_rf['Survived'] = base_teste['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respostas_xgb.to_csv('respostas_rf_titanic6.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Conclusão\n",
    "Por incrível que pareça, ao submeter ao Kaggle, os três modelos tiveram exatamente a mesma perfomance: 0.78468 de acurácia. Uma acurácia considerada boa para os padrões desta competição, visto que está entre os 17% melhores da competição. Este trabalho foi muito enriquecedor e permitiu desenvolver-me nas técnicas de Machine Learning com um trabalho prático."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}